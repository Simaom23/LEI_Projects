{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82a744af",
   "metadata": {},
   "source": [
    "# Compressão de Imagem - JPEG  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c1dbb6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as clr\n",
    "import scipy.fftpack as fft\n",
    "import cv2\n",
    "\n",
    "# Global Variables\n",
    "Ct = np.array([[0.299, 0.587, 0.114],\n",
    "               [-0.168736, -0.331264, 0.5],\n",
    "               [0.5, -0.418688, -0.081312]])\n",
    "\n",
    "QY = np.array([[16, 11, 10, 16,  24,  40,  51,  61],\n",
    "               [12, 12, 14, 19,  26,  58,  60,  55],\n",
    "               [14, 13, 16, 24,  40,  57,  69,  56],\n",
    "               [14, 17, 22, 29,  51,  87,  80,  62],\n",
    "               [18, 22, 37, 56,  68, 109, 103,  77],\n",
    "               [24, 35, 55, 64,  81, 104, 113,  92],\n",
    "               [49, 64, 78, 87, 103, 121, 120, 101],\n",
    "               [72, 92, 95, 98, 112, 100, 103,  99]])\n",
    "\n",
    "QC = np.array([[17, 18, 24, 47, 99, 99, 99, 99],\n",
    "               [18, 21, 26, 66, 99, 99, 99, 99],\n",
    "               [24, 26, 56, 99, 99, 99, 99, 99],\n",
    "               [47, 66, 99, 99, 99, 99, 99, 99],\n",
    "               [99, 99, 99, 99, 99, 99, 99, 99],\n",
    "               [99, 99, 99, 99, 99, 99, 99, 99],\n",
    "               [99, 99, 99, 99, 99, 99, 99, 99],\n",
    "               [99, 99, 99, 99, 99, 99, 99, 99]])\n",
    "\n",
    "\n",
    "def main():\n",
    "    print(\"\\n#### - JPEG Encoder/Decoder - ####\")\n",
    "    while True:\n",
    "        file = input(\"Enter file name: \")\n",
    "        if not os.path.isfile(file):\n",
    "            print(\"File not found!\")\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    greyCm = colormap([(0, 0, 0), (1, 1, 1)])\n",
    "    global size\n",
    "    img = readImg(file)\n",
    "    size = img.shape\n",
    "\n",
    "    while True:\n",
    "        compressionRate = input(\n",
    "            \"\\nChoose a compression quality between 1 and 100\\nCompression rate: \")\n",
    "        try:\n",
    "            compressionRate = int(compressionRate)\n",
    "            if compressionRate >= 1 and compressionRate <= 100:\n",
    "                break\n",
    "        except:\n",
    "            print(\"Choice not valid!\")\n",
    "\n",
    "    visualize(img)\n",
    "    jpegEncoded = encoder(img, None, compressionRate)\n",
    "    jpegDecoded = decoder(jpegEncoded, None, compressionRate)\n",
    "    visualize(jpegDecoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa0ca7a4",
   "metadata": {},
   "source": [
    "### 1. Compressão de imagens bmp no formato jpeg\n",
    "1. Comprima as imagens fornecidas segundo o codec JPEG, com qualidade alta.\n",
    "2. Comprima as imagens fornecidas segundo o codec JPEG, com qualidade média.\n",
    "3. Comprima as imagens fornecidas segundo o codec JPEG, com qualidade baixa."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b00f6203",
   "metadata": {},
   "source": [
    "| Original | Alta(75) | Média(50) |  Baixa(25)  |\n",
    "| --- | --- | --- | --- |\n",
    "| <img src=\"imagens/logo.bmp\" /> | <img src=\"imagens/logo-high.jpg\" /> | <img src=\"imagens/logo-medium.jpg\" /> | <img src=\"imagens/logo-low.jpg\" /> |\n",
    "| 412Kb | 8Kb | 7Kb | 6Kb |\n",
    "| <img src=\"imagens/peppers.bmp\" /> | <img src=\"imagens/peppers-high.jpg\" /> | <img src=\"imagens/peppers-medium.jpg\" /> | <img src=\"imagens/peppers-low.jpg\" /> |\n",
    "| 580Kb | 24Kb | 16Kb | 12Kb |\n",
    "| <img src=\"imagens/barn_mountains.bmp\" /> | <img src=\"imagens/barn_mountains-high.jpg\" /> | <img src=\"imagens/barn_mountains-medium.jpg\" /> | <img src=\"imagens/barn_mountains-low.jpg\" /> |\n",
    "| 352Kb | 28Kb | 20Kb | 12Kb |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd207f9",
   "metadata": {},
   "source": [
    "4. **Compare os resultados e tire conclusões.**  \n",
    "    É possível observar, nas imagens acima, que a imagem logo nao contém muitas transições abruptas entre pixeis vizinhos, ou seja, não existe muitas frequências espaciais altas o que torna a compressão. Em relação às imagens mais realistas como a peppers ou a barn_mountains, é possivel observar que mesmo com compressão alta a distorção do logo é muito perceptivel, o que já acontece menos na peppers pois já tem uma maior transição abrupta nos pixeis e ainda menos na barn_mountains que existe muitas transições abruptas. Em termos de compressão e a perceção de distorção a barn_mountains vai ser melhor seguida da peppers e por fim do logo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ec531c",
   "metadata": {},
   "source": [
    "### 2. Crie duas funções, encoder e decoder, para encapsular as funções a desenvolver nas alíenas 3 a 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a2bf12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enconde Image to JPEG\n",
    "def encoder(img, conversionTable=None, compressionRate=None):\n",
    "    paddedImg = padding(img, 16)\n",
    "    ycbcrImg = rgb_to_ycbcr(paddedImg)\n",
    "    Y_d, Cb_d, Cr_d = subSampling(ycbcrImg, 2, 2)\n",
    "    Y_dct, Cb_dct, Cr_dct = dct(Y_d, Cb_d, Cr_d, 8)\n",
    "    Y_quant, Cb_quant, Cr_quant = quantization(\n",
    "        Y_dct, Cb_dct, Cr_dct, compressionRate, 8)\n",
    "    Y_quant, Cb_quant, Cr_quant = dpcm(Y_quant, Cb_quant, Cr_quant)\n",
    "\n",
    "    return Y_quant, Cb_quant, Cr_quant\n",
    "\n",
    "# Decode JPEG Image\n",
    "def decoder(img, conversionTable=None, conversionRate=None):\n",
    "    Y_invDpcm, Cb_invDpcm, Cr_invDpcm = invDpcm(img[0], img[1], img[2])\n",
    "    Y_invQuant, Cb_invQuant, Cr_invQuant = invQuantization(\n",
    "        Y_invDpcm, Cb_invDpcm, Cr_invDpcm, conversionRate, 8)\n",
    "    Y_invDct, Cb_invDct, Cr_invDct = invDct(\n",
    "        Y_invQuant, Cb_invQuant, Cr_invQuant, 8)\n",
    "    imgUp = upSampling(Y_invDct, Cb_invDct, Cr_invDct, 2, 2)\n",
    "    rgbImg = ycbcr_to_rgb(imgUp)\n",
    "    decodedImg = unpadding(rgbImg, size)\n",
    "\n",
    "    return decodedImg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d9815f8",
   "metadata": {},
   "source": [
    "### 3. Visualização de imagem representada pelo modelo de cor RGB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e81b46",
   "metadata": {},
   "source": [
    "1. Leia uma imagem .bmp, e.g., a imagem peppers.bmp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1251b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reads Image Data\n",
    "def readImg(file):\n",
    "    image = plt.imread(file)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c84cba",
   "metadata": {},
   "source": [
    "2. Crie uma função para implementar um colormap definido pelo utilizador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a1cc18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Colormap\n",
    "def colormap(value):\n",
    "    # If we want to visualize the colormap\n",
    "    nl = 5\n",
    "    nc = 50\n",
    "    linGray = np.linspace(0., 1., nc).reshape(1, nc)\n",
    "    linGray = np.repeat(linGray, nl, axis=1).reshape(nc, nl).T\n",
    "    linGrayImg = np.zeros((nl, nc, 3))\n",
    "    linGrayImg[:, :, 0] = linGray\n",
    "    linGrayImg[:, :, 1] = linGray\n",
    "    linGrayImg[:, :, 2] = linGray\n",
    "    \n",
    "    cm = clr.LinearSegmentedColormap.from_list('cmap', value, N=256)\n",
    "    return cm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a186dac",
   "metadata": {},
   "source": [
    "3. Crie uma função que permita visualizar a imagem com um dado colormap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28995615",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Image\n",
    "def visualize(img, cm=None, log=False):\n",
    "    if log:\n",
    "        img = np.log(np.abs(img) + 0.0001)\n",
    "    plt.figure()\n",
    "    plt.imshow(img, cm)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe8936dd",
   "metadata": {},
   "source": [
    "4. Crie uma função para separar a imagem nos seus componentes RGB. Crie também a função inversa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44bed6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separates RGB Channels\n",
    "def channelSep(imgData):\n",
    "    red = imgData[:, :, 0]\n",
    "    green = imgData[:, :, 1]\n",
    "    blue = imgData[:, :, 2]\n",
    "\n",
    "    return red, green, blue \n",
    "\n",
    "# Unifie RGB Channels\n",
    "def channelUni(red, green, blue):\n",
    "    auxImage = np.array(red)\n",
    "    auxImage[:, :, 1] = green[:, :, 1]\n",
    "    auxImage[:, :, 2] = blue[:, :, 2]\n",
    "    \n",
    "    return auxImage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc5f475",
   "metadata": {},
   "source": [
    "5. Visualize a imagem e cada um dos canais RGB (com o colormap adequado)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dadaa2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize RGB Channels\n",
    "def visualizeRGB(red, green, blue):\n",
    "    redCm = colormap([(0, 0, 0), (1, 0, 0)])\n",
    "    greenCm = colormap([(0, 0, 0), (0, 1, 0)])\n",
    "    blueCm = colormap([(0, 0, 0), (0, 0, 1)])\n",
    "    \n",
    "    visualize(red, redCm)\n",
    "    visualize(green, greenCm)\n",
    "    visualize(blue, blueCm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc588aa",
   "metadata": {},
   "source": [
    "| Red | Green  | Blue  |\n",
    "| --- | --- | --- |\n",
    "| <img src=\"rgbChannels/peppers-red.svg\" /> | <img src=\"rgbChannels/peppers-green.svg\" /> | <img src=\"rgbChannels/peppers-blue.svg\" /> |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37852723",
   "metadata": {},
   "source": [
    "### 4. Pré-processamento da imagem: padding\n",
    "1. Crie uma função para fazer padding da imagem. Caso a dimensão da imagem não seja múltipla de 16x16, faça padding da mesma, replicando a última linha e a última coluna em conformidade. Crie também a função inversa. Certifique-se de que recupera a imagem com a dimensão original, visualizando-a."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a807b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad Image\n",
    "def padding(img):\n",
    "    imgShape = img.shape\n",
    "    red = img[:, :, 0]\n",
    "    green = img[:, :, 1]\n",
    "    blue = img[:, :, 2]\n",
    "\n",
    "    # Número de linhas a adicionar\n",
    "    if imgShape[0] % 16 != 0:\n",
    "        r = 16 - (imgShape[0] % 16)\n",
    "        red = np.vstack([red, np.tile(red[-1, :], (r, 1))])\n",
    "        green = np.vstack([green, np.tile(green[-1, :], (r, 1))])\n",
    "        blue = np.vstack([blue, np.tile(blue[-1, :], (r, 1))])\n",
    "\n",
    "    # Número de colunas a adicionar\n",
    "    if imgShape[1] % 16 != 0:\n",
    "        c = 16 - (imgShape[1] % 16)\n",
    "        red = np.column_stack([red, np.tile(red[:, -1], (c, 1)).T])\n",
    "        green = np.column_stack([green, np.tile(green[:, -1], (c, 1)).T])\n",
    "        blue = np.column_stack([blue, np.tile(blue[:, -1], (c, 1)).T])\n",
    "\n",
    "    paddedImg = np.zeros((red.shape[0], red.shape[1], 3), np.uint8)\n",
    "    paddedImg[:, :, 0] = red\n",
    "    paddedImg[:, :, 1] = green\n",
    "    paddedImg[:, :, 2] = blue\n",
    "\n",
    "    return paddedImg\n",
    "\n",
    "# Unpad Image\n",
    "def unpadding(paddedImg, shapeImg):\n",
    "    unpaddedImg = paddedImg[:shapeImg[0], :shapeImg[1], :]\n",
    "\n",
    "    return unpaddedImg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f72e0b1",
   "metadata": {},
   "source": [
    "| Unpadded | Padded |\n",
    "| --- | --- |\n",
    "| <img src=\"paddingImages/barn_mountains-unpadded.svg\" /> | <img src=\"paddingImages/barn_mountains-padded.svg\" /> |\n",
    "| Shape - (297, 400, 3) | Shape - (304, 400, 3) |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e4003c7",
   "metadata": {},
   "source": [
    "### 5. Conversão para o modelo cor YCbCr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52551299",
   "metadata": {},
   "source": [
    "1. Crie uma função para converter a imagem do modelo de cor RGB para o modelo de cor YCbCr. Crie também a função inversa (conversão de YCbCr para RGB). Certifique-se de que consegue obter os valores originais de RGB (teste, por exemplo, com o pixel [0, 0]). Nota: na conversão inversa, garanta que R, G e B sejam número inteiros no intervalo {0, 1, …, 255}.\n",
    "2. Converta a imagem inicial para o modelo de cor YCbCr."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c9c43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert RGB to YCbCr\n",
    "def rgb_to_ycbcr(img):\n",
    "    convertedImg = img.dot(Ct.T)\n",
    "    convertedImg[:, :, [1, 2]] += 128\n",
    "\n",
    "    return convertedImg\n",
    "\n",
    "# Convert YCbCr to RGB\n",
    "def ycbcr_to_rgb(img):\n",
    "    invertedCt = np.linalg.inv(Ct.T)\n",
    "    img[:, :, [1, 2]] -= 128\n",
    "    convertedImg = img.dot(invertedCt)\n",
    "    convertedImg = convertedImg.round()\n",
    "    convertedImg[convertedImg > 255] = 255\n",
    "    convertedImg[convertedImg < 0] = 0\n",
    "    convertedImg = convertedImg.astype(np.uint8)\n",
    "\n",
    "    return convertedImg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d12edd",
   "metadata": {},
   "source": [
    "3. Visualize cada um dos canais (com o colormap adequado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae9c593",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize YCbCr Channels\n",
    "def visualizeYCbCr(ycbcrImg):\n",
    "    greyCm = colormap([(0, 0, 0), (1, 1, 1)])\n",
    "    \n",
    "    visualize(ycbcrImg[:, :, 0], greyCm)\n",
    "    visualize(ycbcrImg[:, :, 1], greyCm)\n",
    "    visualize(ycbcrImg[:, :, 2], greyCm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc47d23b",
   "metadata": {},
   "source": [
    "| Y | Cb  | Cr  |\n",
    "| --- | --- | --- |\n",
    "| <img src=\"ycbcrChannels/peppers-Y.svg\" /> | <img src=\"ycbcrChannels/peppers-Cb.svg\" /> | <img src=\"ycbcrChannels/peppers-Cr.svg\" /> |\n",
    "\n",
    "| R | G  | B |\n",
    "| --- | --- | --- |\n",
    "| <img src=\"rgbChannels/peppers-red.svg\" /> | <img src=\"rgbChannels/peppers-green.svg\" /> | <img src=\"rgbChannels/peppers-blue.svg\" /> |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2551e4",
   "metadata": {},
   "source": [
    "4. **Compare a imagem de Y com R, G e B e com Cb e Cr. Tire conclusões.**  \n",
    "    Na imagem RGB a luminância e o detalhe são distribuidos pelos três canais contendo muita informação redundante, quando é convertida para YCbCr passam a estar no canal Y. Comparando os dois esquemas podemos observar que o canal Y contem muita informação e detalhe e os canais da crominânica contêm pouca informação pois não existe tanta sensibilidade por parte do ser humano então aí teremos uma possibilidade de compressão desses canais."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d65e2d33",
   "metadata": {},
   "source": [
    "### 6. Sub-Amostragem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "720f000d",
   "metadata": {},
   "source": [
    "1. Crie uma função para sub-amostrar os canais Y, Cb, e Cr, segundo as possibilidades definidas pelo codec JPEG, a qual deve devolver Y_d, Cb_d e Cr_d. Crie também a função para efectuar a operação inversa, i.e., upsampling. Certifique-se de que consegue reconstruir com exactidão Y, Cb e Cr."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120dc9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SubSampling Image\n",
    "def subSampling(img, factorX, factorY):\n",
    "    Y_d = img[:, :, 0]\n",
    "    # Cb_d = cv2.resize(img, None, fx=1/factorX, fy=1/factorY, interpolation=cv2.INTER_LINEAR)\n",
    "    # Cr_d = cv2.resize(img, None, fx=1/factorX, fy=1/factorY, interpolation=cv2.INTER_LINEAR)\n",
    "    Cb_d = img[:, :, 1][::factorX, ::factorY]\n",
    "    Cr_d = img[:, :, 2][::factorX, ::factorY]\n",
    "\n",
    "    return Y_d, Cb_d, Cr_d\n",
    "\n",
    "# UpSampling Image\n",
    "def upSampling(Y_d, Cb_d, Cr_d, factorX, factorY):\n",
    "    Y_u = Y_d\n",
    "    # Cb_u = cv2.resize(Cb_d, None, fx=factorX, fy=factorY, interpolation=cv2.INTER_LINEAR)\n",
    "    # Cr_u = cv2.resize(Cr_d, None, fx=factorX, fy=factorY, interpolation=cv2.INTER_LINEAR)\n",
    "    Cb_u = np.repeat(Cb_d, factorX, axis=0)\n",
    "    Cr_u = np.repeat(Cr_d, factorX, axis=0)\n",
    "    Cb_u = np.repeat(Cb_u, factorY, axis=1)\n",
    "    Cr_u = np.repeat(Cr_u, factorY, axis=1)\n",
    "    imgUp = np.dstack([Y_u, Cb_u, Cr_u])\n",
    "\n",
    "    return imgUp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b9bbe1",
   "metadata": {},
   "source": [
    "2. Visualize os canais Y_d, Cb_d e Cr_d com downsampling 4:2:0. Apresente as dimensões das matrizes correspondentes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c57e5d64",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "<h4>4:2:0</h4>\n",
    "\n",
    "| Y | Cb  | Cr  |\n",
    "| --- | --- | --- |\n",
    "| <img src=\"downsampledImages/peppers-Ysub.svg\" /> | <img src=\"downsampledImages/peppers-Cbsub.svg\" /> | <img src=\"downsampledImages/peppers-Crsub.svg\" /> |\n",
    "| (384, 512) | (192, 256) | (192, 256) |\n",
    "\n",
    "<h4>4:2:2</h4>\n",
    "\n",
    "| Y | Cb  | Cr |\n",
    "| --- | --- | --- |\n",
    "| <img src=\"downsampledImages/peppers-Ysub.svg\" /> | <img src=\"downsampledImages/peppers-Cbsub2.svg\" /> | <img src=\"downsampledImages/peppers-Crsub2.svg\" /> |\n",
    "| (384, 512) | (192, 512) | (192, 512) |\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "424959f9",
   "metadata": {},
   "source": [
    "3. **Apresente e analise a taxa de compressão alcançada para as variantes de downsampling 4:2:2 e 4:2:0 (taxa de compressão, destrutividade, etc.)**  \n",
    "    No downsampling 4:2:2 os canais da crominância, Cb e Cr, são amostrados a metade, ou seja, a resolução dos canais são reduzidos a metade o que traz uma taxa de compressão de 1/3 à imagem original. Já no downsampling 4:2:0 tanto a resolução horizontal como vertical são reduzidos a metade o que traz uma taxa de compressão de 1/2 em relação à imagem original. Neste passo já existiu uma grande compressão da imagem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8417e7b1",
   "metadata": {},
   "source": [
    "### 7. Transformada de Coseno Discreta (DCT)\n",
    "#### 1. DCT nos canais completos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef650fb",
   "metadata": {},
   "source": [
    "1. Crie uma função para calcular a DCT de um canal completo. Utilize a função scipy.fftpack.dct. Crie também a função inversa (usando scipy.fftpack.idct). Certifique-se de que consegue obter os valores originais de Y_d, Cb_d e Cr_d. Nota: para uma matriz, X, com duas dimensões, deverá fazer: X_dct = dct(dct(X, norm=”ortho”).T, norm=”ortho”).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c205f6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DCT Image\n",
    "def dct(Y_d, Cb_d, Cr_d):\n",
    "    Y_dct = fft.dct(fft.dct(Y_d, norm=\"ortho\").T, norm=\"ortho\").T\n",
    "    Cb_dct = fft.dct(fft.dct(Cb_d, norm=\"ortho\").T, norm=\"ortho\").T\n",
    "    Cr_dct = fft.dct(fft.dct(Cr_d, norm=\"ortho\").T, norm=\"ortho\").T\n",
    "\n",
    "    return Y_dct, Cb_dct, Cr_dct\n",
    "\n",
    "# Inverse DCT Image\n",
    "def invDct(Y_dct, Cb_dct, Cr_dct):\n",
    "    Y_invDct = fft.idct(fft.idct(Y_dct, norm=\"ortho\").T, norm=\"ortho\").T\n",
    "    Cb_invDct = fft.idct(fft.idct(Cb_dct, norm=\"ortho\").T, norm=\"ortho\").T\n",
    "    Cr_invDct = fft.idct(fft.idct(Cr_dct, norm=\"ortho\").T, norm=\"ortho\").T\n",
    "    \n",
    "    # Verificar se a DCT Inversa está correta\n",
    "    # diffY = Y_d - Y_invDct\n",
    "    # diffY[diffY < 0.000001] = 0.\n",
    "    # diffCb = Cb_d - Cb_invDct\n",
    "    # diffCb[diffCb < 0.000001] = 0.\n",
    "    # diffCr = Cr_d - Cr_invDct\n",
    "    # diffCr[diffCr < 0.000001] = 0.\n",
    "    \n",
    "    return Y_invDct,  Cb_invDct, Cr_invDct\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4808e324",
   "metadata": {},
   "source": [
    "2. Aplique a função desenvolvida a Y_d, Cb_d, Cr_d e visualize as imagens obtidas(Y_dct, Cb_dct, Cr_dct). Sugestão: atendendo à gama ampla de valores da DCT, visualize as imagens usando uma transformação logarítmica, e.g., de acordo com o seguinte pseudo-código: imshow(log(abs(X) + 0.0001))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51522551",
   "metadata": {},
   "source": [
    "#### barn_mountains.bmp\n",
    "| Y - DCT log | Cb - DCT log | Cr - DCT log |\n",
    "| --- | --- | --- |\n",
    "| <img src=\"dctImages/barn_mountains-Ydct.svg\" /> | <img src=\"dctImages/barn_mountains-Cbdct.svg\" /> | <img src=\"dctImages/barn_mountains-Crdct.svg\" /> |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a88cdca8",
   "metadata": {},
   "source": [
    "3. **Discuta os resultados obtidos em termos de potencial de compressão.**  \n",
    "    Nas imagens acima, é possível observar que as frequências espaciais mais baixas e mais importante concentram-se todas no canto superior esquerdo, sendo que o resto são tudo frequências espaciais altas e são possiveis de as eliminar ou reduzir o número de bits para as representar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e79e02c3",
   "metadata": {},
   "source": [
    "#### 2. DCT em blocos 8x8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcefa409",
   "metadata": {},
   "source": [
    "1. Usando as mesmas funções para cálculo da DCT, crie uma função que calcule a DCT de um canal completo em blocos BSxBS. Crie também a função inversa (IDCT BSxBS). Certifique-se de que consegue obter os valores originais de Y_d, Cb_d e Cr_d."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94d71016",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DCT Image\n",
    "def dct(Y_dct, Cb_dct, Cr_dct, n):\n",
    "    sizeY = Y_dct.shape\n",
    "    sizeC = Cb_dct.shape\n",
    "    for i in range(0, sizeY[0], n):\n",
    "        for j in range(0, sizeY[1], n):\n",
    "            Y_dct[i:i + n, j:j +\n",
    "                  n] = fft.dct(fft.dct(Y_dct[i:i + n, j:j + n], norm=\"ortho\").T, norm=\"ortho\").T\n",
    "            if i < sizeC[0] and j < sizeC[1]:\n",
    "                Cb_dct[i:i + n, j:j + n] = fft.dct(\n",
    "                    fft.dct(Cb_dct[i:i + n, j:j + n], norm=\"ortho\").T, norm=\"ortho\").T\n",
    "                Cr_dct[i:i + n, j:j + n] = fft.dct(\n",
    "                    fft.dct(Cr_dct[i:i + n, j:j + n], norm=\"ortho\").T, norm=\"ortho\").T\n",
    "\n",
    "    return Y_dct, Cb_dct, Cr_dct\n",
    "\n",
    "# Inverse DCT Image\n",
    "def invDct(Y_invDct, Cb_invDct, Cr_invDct, n):\n",
    "    sizeY = Y_invDct.shape\n",
    "    sizeC = Cb_invDct.shape\n",
    "    for i in range(0, sizeY[0], n):\n",
    "        for j in range(0, sizeY[1], n):\n",
    "            Y_invDct[i:i + n, j:j +\n",
    "                     n] = fft.idct(fft.idct(Y_invDct[i:i + n, j:j + n], norm=\"ortho\").T, norm=\"ortho\").T\n",
    "            if i < sizeC[0] and j < sizeC[1]:\n",
    "                Cb_invDct[i:i + n, j:j + n] = fft.idct(\n",
    "                    fft.idct(Cb_invDct[i:i + n, j:j + n], norm=\"ortho\").T, norm=\"ortho\").T\n",
    "                Cr_invDct[i:i + n, j:j + n] = fft.idct(\n",
    "                    fft.idct(Cr_invDct[i:i + n, j:j + n], norm=\"ortho\").T, norm=\"ortho\").T\n",
    "\n",
    "    Y_invDct[Y_invDct < 0] = 0\n",
    "    Y_invDct[Y_invDct > 255] = 255\n",
    "\n",
    "    Cb_invDct[Cb_invDct < 0] = 0\n",
    "    Cb_invDct[Cb_invDct > 255] = 255\n",
    "\n",
    "    Cr_invDct[Cr_invDct < 0] = 0\n",
    "    Cr_invDct[Cr_invDct > 255] = 255\n",
    "\n",
    "    return Y_invDct,  Cb_invDct, Cr_invDct"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b691316e",
   "metadata": {},
   "source": [
    "2. Aplique a função desenvolvida (DCT) a Y_d, Cb_d, Cr_d com blocos 8x8 e visualize as imagens obtidas (Y_DCT8, Cb_DCT8, Cr_DCT8)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2bed1f3",
   "metadata": {},
   "source": [
    "| Y_d | Cb_d  | Cr_d  |\n",
    "| --- | --- | --- |\n",
    "| <img src=\"dctblocksImages/barn_mountains-Ydct8x8.svg\" /> | <img src=\"dctblocksImages/barn_mountains-Cbdct8x8.svg\" /> | <img src=\"dctblocksImages/barn_mountains-Crdct8x8.svg\" /> |\n",
    "\n",
    "| Y_d Inv | Cb_d Inv  | Cr_d Inv |\n",
    "| --- | --- | --- |\n",
    "| <img src=\"dctblocksImages/barn_mountains-Ydct8x8inv.svg\" /> | <img src=\"dctblocksImages/barn_mountains-Cbdct8x8inv.svg\" /> | <img src=\"dctblocksImages/barn_mountains-Crdct8x8inv.svg\" /> |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf356a8e",
   "metadata": {},
   "source": [
    "3. **Compare os resultados obtidos com os resultados de 7.1.2 e discuta-os em termos de potencial de compressão.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07337c3e",
   "metadata": {},
   "source": [
    "#### 3. DCT em blocos 64x64."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e51f0c4a",
   "metadata": {},
   "source": [
    "1. Repita 7.2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0dfa616",
   "metadata": {},
   "source": [
    "| Y_d | Cb_d  | Cr_d  |\n",
    "| --- | --- | --- |\n",
    "| <img src=\"dctblocksImages/barn_mountains-Ydct64x64.svg\" /> | <img src=\"dctblocksImages/barn_mountains-Cbdct64x64.svg\" /> | <img src=\"dctblocksImages/barn_mountains-Crdct64x64.svg\" /> |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8cec71d",
   "metadata": {},
   "source": [
    "2. **Compare com os resultados anteriores e tire conclusões.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "038994ff",
   "metadata": {},
   "source": [
    "### 8. Quantização"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "237c49fb",
   "metadata": {},
   "source": [
    "1. Crie uma função para quantizar os coeficientes da DCT para cada bloco 8x8. Crie também a função inversa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b21c46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quantitize Image\n",
    "def quantization(Y_dct, Cb_dct, Cr_dct, qf, n):\n",
    "    if (qf == 100):\n",
    "        qy = np.ones((8, 8))\n",
    "        qc = np.ones((8, 8))\n",
    "    elif (qf == 50):\n",
    "        qy = QY\n",
    "        qc = QC\n",
    "    else:\n",
    "        qy = np.round(QY * ((100 - qf) / 50))\n",
    "        qy[qy > 255] = 255\n",
    "        qc = np.round(QC * ((100 - qf) / 50))\n",
    "        qc[qc > 255] = 255\n",
    "\n",
    "    sizeY = Y_dct.shape\n",
    "    sizeC = Cb_dct.shape\n",
    "    for i in range(0, sizeY[0], n):\n",
    "        for j in range(0, sizeY[1], n):\n",
    "            Y_dct[i:i + n, j:j + n] = np.round(Y_dct[i:i + n, j: j + n] / qy)\n",
    "            if i < sizeC[0] and j < sizeC[1]:\n",
    "                Cb_dct[i:i + n, j:j +\n",
    "                       n] = np.round(Cb_dct[i:i + n, j:j + n] / qc)\n",
    "                Cr_dct[i:i + n, j:j +\n",
    "                       n] = np.round(Cr_dct[i:i + n, j: j + n] / qc)\n",
    "\n",
    "    return Y_dct, Cb_dct, Cr_dct\n",
    "\n",
    "# Inverse quantitize Image\n",
    "def invQuantization(Y_dct, Cb_dct, Cr_dct, qf, n):\n",
    "    if (qf == 100):\n",
    "        qy = np.ones(8)\n",
    "        qc = np.ones(8)\n",
    "    elif (qf == 50):\n",
    "        qy = QY\n",
    "        qc = QC\n",
    "    else:\n",
    "        qy = np.round(QY * ((100 - qf) / 50))\n",
    "        qy[qy > 255] = 255\n",
    "        qc = np.round(QC * ((100 - qf) / 50))\n",
    "        qc[qc > 255] = 255\n",
    "\n",
    "    sizeY = Y_dct.shape\n",
    "    sizeC = Cb_dct.shape\n",
    "    for i in range(0, sizeY[0], n):\n",
    "        for j in range(0, sizeY[1], n):\n",
    "            Y_dct[i:i + n, j:j + n] = np.round(Y_dct[i:i + n, j: j + n] * qy)\n",
    "            if i < sizeC[0] and j < sizeC[1]:\n",
    "                Cb_dct[i:i + n, j:j +\n",
    "                       n] = np.round(Cb_dct[i:i + n, j:j + n] * qc)\n",
    "                Cr_dct[i:i + n, j:j +\n",
    "                       n] = np.round(Cr_dct[i:i + n, j:j + n] * qc)\n",
    "\n",
    "    return Y_dct, Cb_dct, Cr_dct"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc700b8",
   "metadata": {},
   "source": [
    "2. Quantize os coeficientes da DCT, usando os seguintes factores de qualidade: 10, 25, 50, 75 e 100. Visualize as imagens obtidas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d37ed59c",
   "metadata": {},
   "source": [
    "|Y Channel | Cb Channel | Cr Channel |\n",
    "| ---  | --- | --- |\n",
    "| Muito Alta(100) | Muito Alta(100) | Muito Alta(100) |\n",
    "|  <img src=\"quantizationImages/Y_q100.svg\" /> | <img src=\"quantizationImages/Cb_q100.svg\" /> | <img src=\"quantizationImages/Cr_q100.svg\" /> |\n",
    "| Alta(75) | Alta(75) | Alta(75) |\n",
    "|  <img src=\"quantizationImages/Y_q75.svg\" /> | <img src=\"quantizationImages/Cb_q75.svg\" /> | <img src=\"quantizationImages/Cr_q75.svg\" /> |\n",
    "| Média(50) | Média(50) | Média(50) |\n",
    "|  <img src=\"quantizationImages/Y_q50.svg\" /> | <img src=\"quantizationImages/Cb_q50.svg\" /> | <img src=\"quantizationImages/Cr_q50.svg\" /> |\n",
    "| Baixa(25) | Baixa(25) | Baixa(25) |\n",
    "|  <img src=\"quantizationImages/Y_q25.svg\" /> | <img src=\"quantizationImages/Cb_q25.svg\" /> | <img src=\"quantizationImages/Cr_q25.svg\" /> |\n",
    "| Muito Baixa(10) | Muito Baixa(10) | Muito Baixa(10) | \n",
    "|  <img src=\"quantizationImages/Y_q10.svg\" /> | <img src=\"quantizationImages/Cb_q10.svg\" /> | <img src=\"quantizationImages/Cr_q10.svg\" /> |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa316bd",
   "metadata": {},
   "source": [
    "3. **Compare os resultados obtidos com os vários factores de qualidade e discuta-os em termos de potencial de compressão**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a63c0c2a",
   "metadata": {},
   "source": [
    "4. **Compare os resultados obtidos com os resultados da alínea 5 e tire conclusões.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "916b18a3",
   "metadata": {},
   "source": [
    "### 9. Codificação DPCM dos coeficientes DC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9320237f",
   "metadata": {},
   "source": [
    "1. Crie uma função para realizar a codificação dos coeficientes DC de cada bloco. Em cada bloco, substitua o valor DC pelo valor da diferença. Crie também a função inversa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718fb21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DPCM Image\n",
    "def dpcm(Y_dct, Cb_dct, Cr_dct):\n",
    "    sizeY = Y_dct.shape\n",
    "    sizeC = Cb_dct.shape\n",
    "    dcY0 = Y_dct[0, 0]\n",
    "    dcCb0 = Cb_dct[0, 0]\n",
    "    dcCr0 = Cr_dct[0, 0]\n",
    "    for i in range(8, sizeY[0], 8):\n",
    "        for j in range(8, sizeY[1], 8):\n",
    "            dcY = Y_dct[i, j]\n",
    "            diffY = dcY - dcY0\n",
    "            Y_dct[i, j] = diffY\n",
    "            dcY0 = dcY\n",
    "            if i < sizeC[0] and j < sizeC[1]:\n",
    "                dcCb = Cb_dct[i, j]\n",
    "                dcCr = Cr_dct[i, j]\n",
    "\n",
    "                diffCb = dcCb - dcCb0\n",
    "                diffCr = dcCr - dcCr0\n",
    "\n",
    "                Cb_dct[i, j] = diffCb\n",
    "                Cr_dct[i, j] = diffCr\n",
    "\n",
    "                dcCb0 = dcCb\n",
    "                dcCr0 = dcCr\n",
    "\n",
    "    return Y_dct, Cb_dct, Cr_dct\n",
    "\n",
    "# Inverse DPCM Image\n",
    "def invDpcm(Y_dct, Cb_dct, Cr_dct):\n",
    "    sizeY = Y_dct.shape\n",
    "    sizeC = Cb_dct.shape\n",
    "    dcY0 = Y_dct[0, 0]\n",
    "    dcCb0 = Cb_dct[0, 0]\n",
    "    dcCr0 = Cr_dct[0, 0]\n",
    "    for i in range(8, sizeY[0], 8):\n",
    "        for j in range(8, sizeY[1], 8):\n",
    "            dcY = Y_dct[i, j]\n",
    "            sumY = dcY0 + dcY\n",
    "            Y_dct[i, j] = sumY\n",
    "            dcY0 = sumY\n",
    "            if i < sizeC[0] and j < sizeC[1]:\n",
    "                dcCb = Cb_dct[i, j]\n",
    "                dcCr = Cr_dct[i, j]\n",
    "\n",
    "                sumCb = dcCb0 + dcCb\n",
    "                sumCr = dcCr0 + dcCr\n",
    "\n",
    "                Cb_dct[i, j] = sumCb\n",
    "                Cr_dct[i, j] = sumCr\n",
    "\n",
    "                dcCb0 = sumCb\n",
    "                dcCr0 = sumCr\n",
    "\n",
    "    return [Y_dct, Cb_dct, Cr_dct]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4cb361",
   "metadata": {},
   "source": [
    "2. Aplique a sua função aos valores da DCT quantizada."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9016e8f",
   "metadata": {},
   "source": [
    "3. Analise os resultados e tire conclusões."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1147884",
   "metadata": {},
   "source": [
    "### 10. Codificação e descodificação end-to-end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561c01fc",
   "metadata": {},
   "source": [
    "1. Codifique as imagens fornecidas com os seguintes parâmetros de qualidade: 10, 25, 50, 75 e 100\n",
    "2. **Visualize as imagens descodificadas. Visualize também a imagem das diferenças entre o canal Y de cada uma das imagens originais e da imagem descodificada respectiva para cada um dos factores de qualidade testados. Calcule as várias métricas de distorção (MSE, RMSE, SNR e PSNR) para cada uma das imagens e factores de qualidade. Tire conclusões.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b3c6dd",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "<h4>Imagens Descodificadas</h4>\n",
    "\n",
    "| Original | Original | Original |\n",
    "| --- | --- | --- | \n",
    "|<img src=\"imagens/logo.bmp\" />  | <img src=\"imagens/peppers.bmp\" />  | <img src=\"imagens/barn_mountains.bmp\" /> |\n",
    "| Muito Alta(100) | Muito Alta(100) | Muito Alta(100) |\n",
    "|  <img src=\"decompressedImages/logo-dec100.svg\" /> | <img src=\"decompressedImages/peppers-dec100.svg\" /> | <img src=\"decompressedImages/barn_mountains-dec100.svg\" /> |\n",
    "| Alta(75) | Alta(75) | Alta(75) |\n",
    "|  <img src=\"decompressedImages/logo-dec75.svg\" /> | <img src=\"decompressedImages/peppers-dec75.svg\" /> | <img src=\"decompressedImages/barn_mountains-dec75.svg\" /> |\n",
    "| Média(50) | Média(50) | Média(50) |\n",
    "|  <img src=\"decompressedImages/logo-dec50.svg\" /> | <img src=\"decompressedImages/peppers-dec50.svg\" /> | <img src=\"decompressedImages/barn_mountains-dec50.svg\" /> |\n",
    "| Baixa(25) | Baixa(25) | Baixa(25) |\n",
    "|  <img src=\"decompressedImages/logo-dec25.svg\" /> | <img src=\"decompressedImages/peppers-dec25.svg\" /> | <img src=\"decompressedImages/barn_mountains-dec25.svg\" /> |\n",
    "| Muito Baixa(10) | Muito Baixa(10) | Muito Baixa(10) | \n",
    "|  <img src=\"decompressedImages/logo-dec10.svg\" /> | <img src=\"decompressedImages/peppers-dec10.svg\" /> | <img src=\"decompressedImages/barn_mountains-dec10.svg\" /> |\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6feaa1ff",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "<h4>Diferenças do Canal Y</h4>\n",
    "\n",
    "| Diff(100) | Diff(100) | Diff(100) |\n",
    "| --- | --- | --- |\n",
    "|  <img src=\"yDiff/logo-diff100.svg\" /> | <img src=\"yDiff/peppers-diff100.svg\" /> | <img src=\"yDiff/barn_mountains-diff100.svg\" /> |\n",
    "| Diff(75) | Diff(75) | Diff(75) |\n",
    "|  <img src=\"yDiff/logo-diff75.svg\" /> | <img src=\"yDiff/peppers-diff75.svg\" /> | <img src=\"yDiff/barn_mountains-diff75.svg\" /> |\n",
    "| Diff(50) | Diff(50) | Diff(50) |\n",
    "|  <img src=\"yDiff/logo-diff50.svg\" /> | <img src=\"yDiff/peppers-diff50.svg\" /> | <img src=\"yDiff/barn_mountains-diff50.svg\" /> |\n",
    "| Diff(25) | Diff(25) | Diff(25) |\n",
    "|  <img src=\"yDiff/logo-diff25.svg\" /> | <img src=\"yDiff/peppers-diff25.svg\" /> | <img src=\"yDiff/barn_mountains-diff25.svg\" /> |\n",
    "| Diff(10) | Diff(10) | Diff(10) |\n",
    "|  <img src=\"yDiff/logo-diff10.svg\" /> | <img src=\"yDiff/peppers-diff10.svg\" /> | <img src=\"yDiff/barn_mountains-diff10.svg\" /> |\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed37c1e",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "<h4>Logo Distortion</h4>\n",
    "\n",
    "| Distortion Calculation | CompressionRate(10) | CompressionRate(25) | CompressionRate(50) | CompressionRate(75) | CompressionRate(100) |\n",
    "| --- | --- | --- | --- | --- | --- |\n",
    "| MSE | 100.3356512455516 | 96.39738078291815 | 84.93334519572954 | 62.13719572953737 | 43.08691103202847 |\n",
    "| RMSE | 10.016768503142698 | 9.818216782232819 | 9.215928884042539 | 7.882714997355757 | 6.564062083194252 |\n",
    "| SNR | 31.317565894823957 | 31.491466295313742 | 32.04133633761491 | 33.398602138420934 | 34.98866503407382 |\n",
    "| PSNR | 28.116250869884986 | 28.290151270374764 | 28.840021312675933 | 30.197287113481963 | 31.78735000913484 |\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c99561",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "<h4>Peppers Distortion</h4>\n",
    "\n",
    "\n",
    "| Distortion Calculation | CompressionRate(10) | CompressionRate(25) | CompressionRate(50) | CompressionRate(75) | CompressionRate(100) |\n",
    "| --- | --- | --- | --- | --- | --- |\n",
    "| MSE | 177.6107635498047 | 161.6694132486979 | 133.53300984700522 | 104.56081644694011 | 62.27788289388021 |\n",
    "| RMSE | 13.32706882813339 | 12.714928755156196 | 11.55564839578486 | 10.225498347119329 | 7.891633727808217 |\n",
    "| SNR | 22.431259359027575 | 22.839673550923116 | 23.670065790615137 | 24.732262515068832 | 26.982613766949445 |\n",
    "| PSNR | 25.636110795568612 | 26.04452498746415 | 26.87491722715617 | 27.937113951609874 | 30.18746520349049 |\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "975ae364",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "<h4>Barn Mountains Distortion</h4>\n",
    "\n",
    "| Distortion Calculation | CompressionRate(10) | CompressionRate(25) | CompressionRate(50) | CompressionRate(75) | CompressionRate(100) |\n",
    "| --- | --- | --- | --- | --- | --- |\n",
    "| MSE | 406.7184848484848 | 369.03262626262625 |  293.16542087542086 | 187.50007575757576 | 55.53707912457912 |\n",
    "| RMSE | 20.167262700934028 | 19.21022192122273 |  17.122074082173015 | 13.693066703904416 | 7.4523203852611655 |\n",
    "| SNR | 21.0933366982159 | 21.515628168825938 |  22.515148372520578 | 24.45626133281708 | 29.740445457608157|\n",
    "| PSNR | 22.037864498715727 | 22.46015596932576 |  23.459676173020398 | 25.400789133316902 | 30.68497325810798 |\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "036f940e",
   "metadata": {},
   "source": [
    "3. Volte a analisar o ponto 1, de forma a validar/complementar as conclusões tiradas nesse ponto."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
